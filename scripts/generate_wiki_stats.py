#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitHub CVE Monitor - Wikiç»Ÿè®¡æ•°æ®ç”Ÿæˆè„šæœ¬

åŠŸèƒ½:
1. ä»daily_summary.jsonæå–ç»Ÿè®¡æ•°æ®
2. ç”ŸæˆCVEåˆ†ç±»ç»Ÿè®¡ï¼ˆæ”¯æŒä»CVE APIè·å–CWEï¼‰
3. ç”ŸæˆPOC/EXPç»Ÿè®¡
4. ä»CVE APIè·å–å‚å•†å’Œäº§å“ç»Ÿè®¡
5. è®¡ç®—è¶‹åŠ¿æ•°æ®
6. ç”Ÿæˆä¾›Wikiä½¿ç”¨çš„ç»Ÿè®¡æ•°æ®æ–‡ä»¶
"""

import os
import json
import re
import time
import requests
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import argparse
from pathlib import Path

# APIè¯·æ±‚é…ç½®
CVE_API_URL = "https://cveawg.mitre.org/api/cve/{cve_id}"
API_TIMEOUT = 5  # ç§’
API_RETRY_MAX = 3
API_RETRY_DELAY = 2  # ç§’

def load_daily_summary(summary_path):
    """åŠ è½½æ¯æ—¥æ±‡æ€»æ•°æ®"""
    try:
        with open(summary_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âŒ æ±‡æ€»æ–‡ä»¶æœªæ‰¾åˆ°: {summary_path}")
        return None
    except json.JSONDecodeError:
        print(f"âŒ æ±‡æ€»æ–‡ä»¶æ ¼å¼é”™è¯¯: {summary_path}")
        return None

def load_daily_files(daily_dir, days=30):
    """åŠ è½½æœ€è¿‘Nå¤©çš„æ¯æ—¥JSONæ–‡ä»¶ - ä¿®æ”¹ä¸ºè¯»å–ç›®å½•ä¸­æ‰€æœ‰JSONæ–‡ä»¶"""
    daily_files = []
    
    # é¦–å…ˆå°è¯•ç›´æ¥è¯»å–ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶
    try:
        for filename in os.listdir(daily_dir):
            if filename.endswith('.json') and filename != 'daily_summary.json':
                file_path = os.path.join(daily_dir, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        # ç¡®ä¿æ•°æ®åŒ…å«å¿…è¦çš„dateå­—æ®µ
                        if 'date' in data and 'cves' in data:
                            daily_files.append(data)
                except Exception as e:
                    print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        
        print(f"ğŸ“ ç›´æ¥è¯»å–åˆ° {len(daily_files)} ä¸ªJSONæ–‡ä»¶")
        
        # å¦‚æœæ²¡æœ‰è¯»å–åˆ°æ–‡ä»¶ï¼Œå›é€€åˆ°åŸå§‹çš„åŸºäºæ—¥æœŸçš„æ–¹æ³•
        if not daily_files:
            print("âš ï¸  æœªæ‰¾åˆ°JSONæ–‡ä»¶ï¼Œå°è¯•åŸºäºå½“å‰æ—¥æœŸæŸ¥æ‰¾")
            today = datetime.now().date()
            
            for i in range(days):
                target_date = today - timedelta(days=i)
                date_str = target_date.isoformat()
                file_path = os.path.join(daily_dir, f"{date_str}.json")
                
                if os.path.exists(file_path):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            daily_files.append(data)
                    except Exception as e:
                        print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
    except Exception as e:
        print(f"âš ï¸  è¯»å–ç›®å½•å¤±è´¥: {e}")
    
    # æŒ‰æ—¥æœŸæ’åº
    return sorted(daily_files, key=lambda x: x.get('date', ''))

def get_cve_details(cve_id):
    """ä»CVE APIè·å–CVEè¯¦ç»†ä¿¡æ¯"""
    url = CVE_API_URL.format(cve_id=cve_id)
    
    for retry in range(API_RETRY_MAX):
        try:
            response = requests.get(url, timeout=API_TIMEOUT)
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 404:
                print(f"âš ï¸  CVE {cve_id} æœªæ‰¾åˆ°")
                return None
            else:
                print(f"âš ï¸  APIè¯·æ±‚å¤±è´¥: {response.status_code} - é‡è¯•ä¸­ ({retry + 1}/{API_RETRY_MAX})")
        except Exception as e:
            print(f"âš ï¸  APIè¯·æ±‚å¼‚å¸¸: {e} - é‡è¯•ä¸­ ({retry + 1}/{API_RETRY_MAX})")
        
        if retry < API_RETRY_MAX - 1:
            time.sleep(API_RETRY_DELAY)
    
    print(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ— æ³•è·å– {cve_id} çš„ä¿¡æ¯")
    return None

def analyze_cve_types(cve_data):
    """åˆ†æCVEç±»å‹åˆ†å¸ƒï¼ˆæ”¯æŒä»CVE APIè·å–CWEåˆ†ç±»ï¼‰"""
    # 1. å®šä¹‰CWEåˆ†ç±»æ˜ å°„ï¼ˆæ‰©å±•ç‰ˆï¼ŒåŒ…å«ç”¨æˆ·æä¾›çš„CWE-98ï¼‰
    cwe_mapping = {
        # CWE Top 25
        'CWE-79': 'æ³¨å…¥æ”»å‡» - XSS',
        'CWE-89': 'æ³¨å…¥æ”»å‡» - SQL',
        'CWE-352': 'æ³¨å…¥æ”»å‡» - CSRF',
        'CWE-434': 'æ–‡ä»¶ä¸Šä¼ æ¼æ´',
        'CWE-22': 'è·¯å¾„éå†',
        'CWE-444': 'HTTPè¯·æ±‚èµ°ç§',
        'CWE-918': 'æœåŠ¡å™¨ç«¯è¯·æ±‚ä¼ªé€ (SSRF)',
        'CWE-502': 'ååºåˆ—åŒ–æ¼æ´',
        'CWE-20': 'è¾“å…¥éªŒè¯é”™è¯¯',
        'CWE-732': 'æƒé™åˆ†é…é”™è¯¯',
        'CWE-306': 'è®¤è¯ç¼ºå¤±',
        'CWE-311': 'åŠ å¯†ç¼ºå¤±',
        'CWE-862': 'æˆæƒç¼ºå¤±',
        'CWE-125': 'ç¼“å†²åŒºæº¢å‡º - è¶Šç•Œè¯»å–',
        'CWE-416': 'é‡Šæ”¾åä½¿ç”¨(UAF)',
        'CWE-287': 'è®¤è¯ç»•è¿‡',
        'CWE-787': 'ç¼“å†²åŒºæº¢å‡º - è¶Šç•Œå†™å…¥',
        'CWE-94': 'ä»£ç æ³¨å…¥',
        'CWE-611': 'XMLå¤–éƒ¨å®ä½“æ³¨å…¥(XXE)',
        'CWE-77': 'å‘½ä»¤æ³¨å…¥',
        'CWE-269': 'ææƒæ¼æ´',
        'CWE-863': 'æˆæƒé”™è¯¯',
        'CWE-362': 'ç«äº‰æ¡ä»¶',
        'CWE-476': 'ç©ºæŒ‡é’ˆè§£å¼•ç”¨',
        'CWE-190': 'æ•´æ•°æº¢å‡º',
        # æ–°å¢CWEåˆ†ç±»
        'CWE-98': 'ä»£ç æ³¨å…¥ - PHPæ–‡ä»¶åŒ…å«',  # ç”¨æˆ·æä¾›çš„CWE-98ç¤ºä¾‹
        'CWE-400': 'èµ„æºè€—å°½',
        'CWE-284': 'è®¿é—®æ§åˆ¶ä¸å½“',
        'CWE-326': 'å¼±åŠ å¯†',
        'CWE-119': 'å†…å­˜æŸå',
        'CWE-640': 'å¯†ç æ¢å¤é—®é¢˜',
        'CWE-1333': 'æ­£åˆ™è¡¨è¾¾å¼æ‹’ç»æœåŠ¡',
        'CWE-552': 'æ–‡ä»¶æ“ä½œä¸å½“',
        'CWE-601': 'URLé‡å®šå‘æ¼æ´',
        'CWE-749': 'æ•æ„Ÿæƒé™é…ç½®é”™è¯¯'
    }
    
    # 2. åŸºäºå…³é”®è¯çš„ä¼ ç»Ÿåˆ†ç±»ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
    type_patterns = {
        'è¿œç¨‹ä»£ç æ‰§è¡Œ': [r'RCE', r'remote code execution', r'è¿œç¨‹ä»£ç æ‰§è¡Œ', r'code execution'],
        'æ³¨å…¥æ”»å‡»': [r'injection', r'æ³¨å…¥', r'SQL', r'XSS', r'CSRF', r'OGNL', r'å‘½ä»¤æ³¨å…¥', r'æŒ‡ä»¤æ³¨å…¥'],
        'ææƒæ¼æ´': [r'privilege escalation', r'ææƒ', r'æƒé™æå‡', r'elevation'],
        'ä¿¡æ¯æ³„éœ²': [r'info disclosure', r'information disclosure', r'ä¿¡æ¯æ³„éœ²', r'æ•æ„Ÿä¿¡æ¯'],
        'è·¯å¾„éå†': [r'path traversal', r'traversal', r'directory traversal', r'ç›®å½•éå†'],
        'æ‹’ç»æœåŠ¡': [r'DoS', r'denial of service', r'æ‹’ç»æœåŠ¡'],
        'è®¤è¯ç»•è¿‡': [r'bypass', r'authentication bypass', r'ç»•è¿‡', r'auth bypass'],
        'ç¼“å†²åŒºæº¢å‡º': [r'buffer overflow', r'ç¼“å†²åŒºæº¢å‡º', r'overflow'],
        'è·¨ç«™è„šæœ¬': [r'xss', r'cross site scripting', r'è·¨ç«™è„šæœ¬'],
        'SQLæ³¨å…¥': [r'sql injection', r'SQLæ³¨å…¥', r'injection.*sql'],
        'CSRF': [r'csrf', r'cross site request forgery', r'è·¨ç«™è¯·æ±‚ä¼ªé€ '],
        'ååºåˆ—åŒ–': [r'deserialization', r'unserialize', r'ååºåˆ—åŒ–'],
        'SSRF': [r'ssrf', r'server side request forgery', r'æœåŠ¡å™¨ç«¯è¯·æ±‚ä¼ªé€ '],
        'XXE': [r'xxe', r'xml external entity', r'XMLå¤–éƒ¨å®ä½“']
    }
    
    type_count = defaultdict(int)
    unclassified = 0
    api_errors = 0
    cwe_from_api = 0
    cwe_from_local = 0
    keyword_matched = 0
    
    print("ğŸ” å¼€å§‹åˆ†æCVEç±»å‹ï¼Œå°†å°è¯•ä»CVE APIè·å–CWEä¿¡æ¯...")
    
    for day_data in cve_data:
        for cve in day_data.get('cves', []):
            description = cve.get('description', '').lower()
            cve_id = cve.get('cve_id', '').upper()
            classified = False
            
            # 1. ä¼˜å…ˆä»CVE APIè·å–CWEä¿¡æ¯ï¼ˆç”¨æˆ·å»ºè®®çš„æ–¹å¼ï¼‰
            cwe_id = None
            try:
                # è°ƒç”¨APIè·å–è¯¦ç»†ä¿¡æ¯
                cve_details = get_cve_details(cve_id)
                
                if cve_details and 'containers' in cve_details:
                    # è§£æCWEä¿¡æ¯
                    problem_types = cve_details['containers'].get('cna', {}).get('problemTypes', [])
                    for problem_type in problem_types:
                        descriptions = problem_type.get('descriptions', [])
                        for desc in descriptions:
                            if 'cweId' in desc:
                                cwe_id = desc['cweId']
                                break
                        if cwe_id:
                            break
                    
                    if cwe_id:
                        cwe_from_api += 1
                        # ä½¿ç”¨æ ‡å‡†åŒ–çš„CWE IDæ ¼å¼
                        if not cwe_id.startswith('CWE-'):
                            cwe_id = f'CWE-{cwe_id}'
                        
                        # æ˜ å°„åˆ°å‹å¥½åç§°
                        if cwe_id in cwe_mapping:
                            type_count[cwe_mapping[cwe_id]] += 1
                            classified = True
                        else:
                            # å¯¹äºæœªæ˜ å°„çš„CWEï¼Œä½¿ç”¨åŸå§‹ID
                            type_count[cwe_id] += 1
                            classified = True
            except Exception as e:
                api_errors += 1
                print(f"âŒ å¤„ç† {cve_id} æ—¶å‡ºé”™: {e}")
            
            # 2. å¦‚æœAPIè·å–å¤±è´¥ï¼Œå°è¯•ä»æœ¬åœ°æ•°æ®è·å–CWE
            if not classified and 'cwe_info' in cve:
                cwe_info = cve.get('cwe_info', '')
                cwe_match = re.search(r'CWE-(\d+)', cwe_info)
                if cwe_match:
                    cwe_from_local += 1
                    local_cwe_id = f"CWE-{cwe_match.group(1)}"
                    if local_cwe_id in cwe_mapping:
                        type_count[cwe_mapping[local_cwe_id]] += 1
                        classified = True
            
            # 3. å¦‚æœæ²¡æœ‰CWEä¿¡æ¯æˆ–æœªåŒ¹é…ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…
            if not classified:
                for cve_type, patterns in type_patterns.items():
                    for pattern in patterns:
                        if re.search(pattern, description, re.IGNORECASE):
                            keyword_matched += 1
                            type_count[cve_type] += 1
                            classified = True
                            break
                    if classified:
                        break
            
            if not classified:
                unclassified += 1
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"ğŸ“Š CVEç±»å‹åˆ†æç»Ÿè®¡:")
    print(f"   - ä»APIè·å–CWE: {cwe_from_api}ä¸ª")
    print(f"   - ä»æœ¬åœ°è·å–CWE: {cwe_from_local}ä¸ª")
    print(f"   - å…³é”®è¯åŒ¹é…: {keyword_matched}ä¸ª")
    print(f"   - æœªåˆ†ç±»: {unclassified}ä¸ª")
    print(f"   - APIé”™è¯¯: {api_errors}ä¸ª")
    
    # æ·»åŠ æœªåˆ†ç±»
    if unclassified > 0:
        type_count['å…¶ä»–'] = unclassified
    
    # è½¬æ¢ä¸ºæ’åºåçš„åˆ—è¡¨
    result = sorted(type_count.items(), key=lambda x: x[1], reverse=True)
    print(f"âœ… å…±è¯†åˆ« {len(result)} ç§CVEç±»å‹")
    return result

def analyze_poc_exp(cve_data):
    """åˆ†æPOC/EXPç»Ÿè®¡ï¼ˆåŸºäºä»“åº“æ ‡ç­¾å’Œæè¿°å†…å®¹çš„å¤šç»´åº¦åˆ¤æ–­ï¼‰"""
    # å¢å¼ºçš„POCå…³é”®è¯åˆ—è¡¨
    poc_keywords = [
        'poc', 'proof of concept', 'éªŒè¯è„šæœ¬', 'æ¦‚å¿µéªŒè¯',
        'demonstration', 'æ¼”ç¤ºä»£ç ', 'test case', 'æµ‹è¯•ç”¨ä¾‹',
        'verify', 'éªŒè¯', 'confirm', 'ç¡®è®¤', 'reproduce', 'å¤ç°'
    ]
    
    # å¢å¼ºçš„EXPå…³é”®è¯åˆ—è¡¨
    exp_keywords = [
        'exp', 'exploit', 'æ¼æ´åˆ©ç”¨', 'åˆ©ç”¨ä»£ç ',
        'attack', 'æ”»å‡»', 'payload', 'æœ‰æ•ˆè½½è·',
        'shell', 'åå¼¹', 'reverse shell', 'shellcode',
        'exploitable', 'å¯åˆ©ç”¨', 'exploit code', 'åˆ©ç”¨å·¥å…·'
    ]
    
    # ä»“åº“æ ‡ç­¾å…³é”®è¯ï¼ˆé«˜æƒé‡æŒ‡æ ‡ï¼‰
    repo_tags = {
        'poc_tags': ['poc', 'proof-of-concept', 'cve-poc', 'vulnerability-poc'],
        'exp_tags': ['exploit', 'exploit-code', 'cve-exploit', 'vulnerability-exploit']
    }
    
    # æ–‡ä»¶æ‰©å±•åæŒ‡æ ‡
    file_extensions = {
        'poc_exts': ['.py', '.js', '.sh', '.java', '.go'],
        'exp_exts': ['.py', '.c', '.cpp', '.sh', '.js', '.asm']
    }
    
    poc_count = 0
    exp_count = 0
    both_count = 0
    neither_count = 0
    
    for day_data in cve_data:
        for cve in day_data.get('cves', []):
            # è·å–å„ç§æ•°æ®æº
            repo_info = cve.get('repo_info', '').lower()
            description = cve.get('description', '').lower()
            repo_name = cve.get('repo_name', '').lower()
            repo_tags_text = cve.get('repo_tags', '').lower()
            file_list = cve.get('file_list', '').lower()
            
            # ç»„åˆæ‰€æœ‰æ–‡æœ¬å†…å®¹
            content = f"{repo_info} {description} {repo_name} {file_list}"
            
            # 1. åŸºäºæ ‡ç­¾çš„é«˜æƒé‡åˆ¤æ–­
            has_poc_tag = any(tag in repo_tags_text for tag in repo_tags['poc_tags'])
            has_exp_tag = any(tag in repo_tags_text for tag in repo_tags['exp_tags'])
            
            # 2. åŸºäºå…³é”®è¯çš„åˆ¤æ–­
            has_poc_keyword = any(keyword in content for keyword in poc_keywords)
            has_exp_keyword = any(keyword in content for keyword in exp_keywords)
            
            # 3. åŸºäºæ–‡ä»¶åçš„åˆ¤æ–­
            has_poc_ext = any(ext in file_list and ('poc' in file_list or 'proof' in file_list) 
                            for ext in file_extensions['poc_exts'])
            has_exp_ext = any(ext in file_list and ('exp' in file_list or 'exploit' in file_list) 
                            for ext in file_extensions['exp_exts'])
            
            # ç»¼åˆåˆ¤æ–­é€»è¾‘
            has_poc = has_poc_tag or (has_poc_keyword and has_poc_ext) or (has_poc_keyword and not has_exp_keyword)
            has_exp = has_exp_tag or (has_exp_keyword and has_exp_ext) or (has_exp_keyword and not has_poc_keyword)
            
            # ä»“åº“åä¸­åŒ…å«æ˜ç¡®çš„poc/exploitæ ‡è¯†
            if 'poc' in repo_name and 'exploit' not in repo_name:
                has_poc = True
            elif 'exploit' in repo_name:
                has_exp = True
            
            # ç»Ÿè®¡ç»“æœ
            if has_poc and has_exp:
                both_count += 1
            elif has_poc:
                poc_count += 1
            elif has_exp:
                exp_count += 1
            else:
                neither_count += 1
    
    return {
        'ä»…POC': poc_count,
        'ä»…EXP': exp_count,
        'POC+EXP': both_count,
        'æ— POC/EXP': neither_count
    }

def calculate_trends(growth_stats, days=7):
    """è®¡ç®—è¶‹åŠ¿æ•°æ®"""
    if len(growth_stats) < days:
        return growth_stats
    
    # ç¡®ä¿è¿”å›çš„æ•°æ®ç»“æ„ä¸€è‡´ï¼Œå¤„ç†é”®åå¯èƒ½ä¸åŒ¹é…çš„æƒ…å†µ
    result = []
    for item in growth_stats[-days:]:
        # å¤„ç†å¯èƒ½çš„é”®åå·®å¼‚
        formatted_item = {
            'date': item.get('date', ''),
            'daily_count': item.get('daily_count', item.get('count', 0)),
            'cumulative_total': item.get('cumulative_total', item.get('cumulative', 0)),
            'growth_rate': item.get('growth_rate', 0)
        }
        result.append(formatted_item)
    
    return result

def analyze_vendor_product_stats(cve_data):
    """ä»CVE APIè·å–å‚å•†å’Œäº§å“ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ›¿ä»£æŒ‡çº¹ç»Ÿè®¡ï¼‰"""
    vendor_count = defaultdict(int)
    product_count = defaultdict(int)
    vendor_product_pairs = defaultdict(int)
    
    api_success = 0
    api_failure = 0
    
    print("ğŸ¢ å¼€å§‹åˆ†æå‚å•†å’Œäº§å“ä¿¡æ¯ï¼Œä»CVE APIè·å–å‡†ç¡®æ•°æ®...")
    
    for day_data in cve_data:
        for cve in day_data.get('cves', []):
            cve_id = cve.get('cve_id', '').upper()
            
            try:
                # è°ƒç”¨APIè·å–è¯¦ç»†ä¿¡æ¯
                cve_details = get_cve_details(cve_id)
                
                if cve_details and 'containers' in cve_details:
                    # è§£æå‚å•†å’Œäº§å“ä¿¡æ¯
                    affected = cve_details['containers'].get('cna', {}).get('affected', [])
                    
                    for item in affected:
                        vendor = item.get('vendor', '').strip()
                        product = item.get('product', '').strip()
                        
                        if vendor:
                            vendor_count[vendor] += 1
                            api_success += 1
                            
                            if product:
                                product_count[product] += 1
                                # ä¿å­˜å‚å•†-äº§å“å¯¹
                                vendor_product_pairs[f"{vendor} - {product}"] += 1
            except Exception as e:
                api_failure += 1
                print(f"âŒ è·å– {cve_id} çš„å‚å•†/äº§å“ä¿¡æ¯å¤±è´¥: {e}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"ğŸ“Š å‚å•†/äº§å“åˆ†æç»Ÿè®¡:")
    print(f"   - APIæˆåŠŸ: {api_success}æ¬¡")
    print(f"   - APIå¤±è´¥: {api_failure}æ¬¡")
    print(f"   - è¯†åˆ«å‚å•†æ•°: {len(vendor_count)}")
    print(f"   - è¯†åˆ«äº§å“æ•°: {len(product_count)}")
    
    # è½¬æ¢ä¸ºæ’åºåçš„åˆ—è¡¨
    sorted_vendors = sorted(vendor_count.items(), key=lambda x: x[1], reverse=True)
    sorted_products = sorted(product_count.items(), key=lambda x: x[1], reverse=True)
    sorted_pairs = sorted(vendor_product_pairs.items(), key=lambda x: x[1], reverse=True)
    
    print(f"âœ… å‚å•†ç»Ÿè®¡Top 10: {[(v[0], v[1]) for v in sorted_vendors[:10]]}")
    
    # è¿”å›æ•´åˆçš„ç»Ÿè®¡ç»“æœ
    return {
        'vendors': dict(sorted_vendors[:15]),  # Top 15å‚å•†
        'products': dict(sorted_products[:15]),  # Top 15äº§å“
        'vendor_product_pairs': dict(sorted_pairs[:10])  # Top 10å‚å•†-äº§å“å¯¹
    }

def analyze_fingerprint_stats(cve_data):
    """ç”ŸæˆæŒ‡çº¹ç»Ÿè®¡ï¼ˆåŸºäºFingerprintHubçš„æŒ‡çº¹åº“æ¦‚å¿µï¼‰- ä¿ç•™ä½œä¸ºå¤‡ç”¨"""
    # å‚è€ƒFingerprintHubçš„æŠ€æœ¯æ ˆæŒ‡çº¹åˆ†ç±»
    technology_patterns = {
        # Webæ¡†æ¶
        'ThinkPHP': [r'thinkphp', r'tp'],
        'Spring': [r'spring', r'boot', r'cloud', r'mvc'],
        'Django': [r'django'],
        'Flask': [r'flask'],
        'Express': [r'express', r'express.js'],
        'Laravel': [r'laravel', r'lumen'],
        'Symfony': [r'symfony'],
        'Ruby on Rails': [r'rails', r'ror', r'ruby on rails'],
        'Vue.js': [r'vue', r'vue\.js'],
        'React': [r'react', r'react\.js'],
        
        # æ•°æ®åº“
        'MySQL': [r'mysql', r'mariadb'],
        'PostgreSQL': [r'postgresql', r'postgres'],
        'MongoDB': [r'mongodb', r'mongo'],
        'Redis': [r'redis'],
        'Elasticsearch': [r'elasticsearch', r'elastic'],
        'Oracle': [r'oracle', r'oci'],
        
        # æœåŠ¡å™¨è½¯ä»¶
        'Apache': [r'apache', r'httpd'],
        'Nginx': [r'nginx', r'engine x'],
        'IIS': [r'iis', r'internet information services'],
        'Tomcat': [r'tomcat'],
        'WebLogic': [r'weblogic'],
        'JBoss': [r'jboss', r'wildfly'],
        
        # æ“ä½œç³»ç»Ÿ
        'Windows': [r'windows', r'win[\d]+', r'ms-'],
        'Linux': [r'linux', r'kernel', r'ubuntu', r'debian', r'redhat', r'centos'],
        'macOS': [r'macos', r'osx'],
        'Android': [r'android'],
        'iOS': [r'ios', r'iphone', r'ipad'],
        
        # ä¸­é—´ä»¶/ç»„ä»¶
        'OpenSSL': [r'openssl'],
        'Redis': [r'redis'],
        'Docker': [r'docker'],
        'Kubernetes': [r'kubernetes', r'k8s'],
        'Nginx': [r'nginx'],
        'Jenkins': [r'jenkins'],
        
        # è¯­è¨€è¿è¡Œæ—¶
        'PHP': [r'php'],
        'Java': [r'java', r'jdk', r'jre'],
        'Python': [r'python', r'pytorch'],
        'JavaScript': [r'javascript', r'js'],
        'Node.js': [r'node\.js', r'node'],
        'Ruby': [r'ruby'],
        'Go': [r'golang', r'go\s'],
        'Rust': [r'rust']
    }
    
    fingerprint_count = defaultdict(int)
    
    for day_data in cve_data:
        for cve in day_data.get('cves', []):
            description = cve.get('description', '').lower()
            cve_id = cve.get('cve_id', '').lower()
            repo_name = cve.get('repo_name', '').lower()
            repo_info = cve.get('repo_info', '').lower()
            
            # ç»„åˆæ‰€æœ‰å¯èƒ½åŒ…å«æŠ€æœ¯æ ˆä¿¡æ¯çš„å†…å®¹
            content = f"{description} {cve_id} {repo_name} {repo_info}"
            
            # å°è¯•åŒ¹é…æ¯ä¸ªæŠ€æœ¯æ ˆæŒ‡çº¹
            matched_technologies = set()
            
            for tech, patterns in technology_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, content, re.IGNORECASE):
                        matched_technologies.add(tech)
                        break
            
            # å¯¹åŒ¹é…çš„æŠ€æœ¯æ ˆè¿›è¡Œè®¡æ•°
            if matched_technologies:
                for tech in matched_technologies:
                    fingerprint_count[tech] += 1
            else:
                # æœªåŒ¹é…åˆ°ç‰¹å®šæŠ€æœ¯æ ˆ
                fingerprint_count['å…¶ä»–'] += 1
    
    # è½¬æ¢ä¸ºæ’åºåçš„åˆ—è¡¨
    return sorted(fingerprint_count.items(), key=lambda x: x[1], reverse=True)

def generate_stats_file(summary, daily_files, output_path):
    """ç”Ÿæˆç»Ÿè®¡æ•°æ®æ–‡ä»¶"""
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    print("ğŸ“Š å¼€å§‹ç”Ÿæˆç»Ÿè®¡æ•°æ®...")
    cve_types = analyze_cve_types(daily_files)
    poc_exp_stats = analyze_poc_exp(daily_files)
    
    # ä½¿ç”¨åŸºäºAPIçš„å‚å•†/äº§å“ç»Ÿè®¡æ›¿ä»£æŒ‡çº¹ç»Ÿè®¡ï¼ˆç”¨æˆ·å»ºè®®ï¼‰
    vendor_product_stats = analyze_vendor_product_stats(daily_files)
    
    # ä¿ç•™æŒ‡çº¹ç»Ÿè®¡ä½œä¸ºå¤‡ç”¨
    fingerprint_stats = analyze_fingerprint_stats(daily_files)
    
    trends = calculate_trends(summary.get('growth_analysis', []))
    
    # å‡†å¤‡ç»Ÿè®¡æ•°æ®
    stats = {
        'generated_at': datetime.now().isoformat(),
        'version': '3.0',  # æ›´æ–°ç‰ˆæœ¬å·
        'summary': {
            'total_cves': summary.get('total_cves', 0),
            'date_range': summary.get('date_range', {}),
            'avg_daily_cves': summary.get('statistics', {}).get('avg_daily_cves', 0),
            'active_days': summary.get('statistics', {}).get('active_days', 0),
            'max_daily_cves': summary.get('statistics', {}).get('max_daily_cves', 0)
        },
        'cve_types': dict(cve_types),
        'poc_exp_stats': poc_exp_stats,
        'vendor_product_stats': vendor_product_stats,  # æ–°å¢åŸºäºAPIçš„å‚å•†/äº§å“ç»Ÿè®¡
        'fingerprint_stats': dict(fingerprint_stats[:15]),  # ä¿ç•™æŒ‡çº¹ç»Ÿè®¡ä½œä¸ºå¤‡ç”¨
        'trends': trends,
        'recent_data': daily_files[-7:]  # æœ€è¿‘7å¤©æ•°æ®
    }
    
    # ä¿å­˜ç»Ÿè®¡æ–‡ä»¶
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
            os.makedirs(output_dir, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        print(f"âœ… ç»Ÿè®¡æ•°æ®æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")
        return stats
    except Exception as e:
        print(f"âŒ ç”Ÿæˆç»Ÿè®¡æ–‡ä»¶å¤±è´¥: {e}")
        return None

def generate_wiki_md(stats, output_md_path):
    """ç”ŸæˆWikiç»Ÿè®¡æ•°æ®Markdown"""
    if not stats:
        return False
    
    # æå–æ•°æ®
    summary = stats.get('summary', {})
    cve_types = stats.get('cve_types', {})
    poc_exp_stats = stats.get('poc_exp_stats', {})
    fingerprint_stats = stats.get('fingerprint_stats', {})
    trends = stats.get('trends', [])
    
    # ç¡®ä¿trendsä¸ä¸ºç©ºæ—¶å†å–æœ€å¤§å€¼
    most_active_day = 'æš‚æ— '
    most_active_count = 0
    if trends:
        # ä¿®å¤é”®åä¸åŒ¹é…é—®é¢˜
        try:
            most_active = max(trends, key=lambda x: x.get('daily_count', x.get('count', 0)))
            most_active_day = most_active.get('date', 'æš‚æ— ')
            most_active_count = most_active.get('daily_count', most_active.get('count', 0))
        except (KeyError, ValueError):
            most_active_day = 'æš‚æ— '
            most_active_count = 0
    
    # ç”ŸæˆMarkdownå†…å®¹
    md_content = f"""
# ç»Ÿè®¡æ•°æ®

æœ¬é¡µé¢å±•ç¤ºGitHub CVEç›‘æ§ç³»ç»Ÿçš„ç»Ÿè®¡æ•°æ®å’Œåˆ†æä¿¡æ¯ï¼Œæ•°æ®è‡ªåŠ¨ä»ç³»ç»Ÿä¸­è·å–å¹¶æ›´æ–°ã€‚

## ğŸ“Š æ€»ä½“ç»Ÿè®¡
- **æ€»CVEè®°å½•æ•°**: {summary.get('total_cves', 0):,}
- **å¹³å‡æ¯æ—¥æ–°å¢**: {summary.get('avg_daily_cves', 0):.1f} ä¸ª
- **æœ€æ´»è·ƒæ—¥æœŸ**: {most_active_day} (å½“æ—¥æ–°å¢ {most_active_count} ä¸ª)
- **ç›‘æµ‹å‘¨æœŸ**: {summary.get('date_range', {}).get('start', 'æš‚æ— ')} è‡³ {summary.get('date_range', {}).get('end', 'æš‚æ— ')}
- **æ´»è·ƒå¤©æ•°**: {summary.get('active_days', 0)} å¤©
- **æ•°æ®æ›´æ–°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ç»Ÿè®¡ç‰ˆæœ¬**: v{stats.get('version', '1.0')} - æ”¯æŒCWEåˆ†ç±»å’ŒæŠ€æœ¯æ ˆæŒ‡çº¹åˆ†æ

## ğŸ“ˆ æ¯æ—¥å¢é•¿è¶‹åŠ¿

| æ—¥æœŸ | æ¯æ—¥æ–°å¢ | ç´¯è®¡æ€»æ•° | å¢é•¿ç‡ |
|:---|:---|:---|:---|
"""
    
    # æ·»åŠ è¶‹åŠ¿è¡¨æ ¼
    for trend in reversed(trends):  # ä»æ–°åˆ°æ—§æ˜¾ç¤º
        growth_icon = "ğŸ“ˆ" if trend['growth_rate'] > 0 else "ğŸ“‰" if trend['growth_rate'] < 0 else "â¡ï¸"
        md_content += f"| {trend['date']} | {trend['daily_count']} | {trend['cumulative_total']:,} | {trend['growth_rate']:+.1f}% {growth_icon} |\n"
    
    # æ·»åŠ CVEç±»å‹ç»Ÿè®¡ï¼ˆæ”¯æŒCWEï¼‰
    if cve_types:
        md_content += "\n## ğŸ” CVEåˆ†ç±»ç»Ÿè®¡ï¼ˆåŸºäºCWEå’Œå…³é”®è¯ï¼‰\n\n| ç±»å‹ | æ•°é‡ | å æ¯” |\n|:---|:---|:---|\n"
        total_types = sum(cve_types.values())
        for cve_type, count in cve_types.items():
            percentage = (count / total_types * 100) if total_types > 0 else 0
            md_content += f"| {cve_type} | {count:,} | {percentage:.1f}% |\n"
    else:
        md_content += "\n## ğŸ” CVEåˆ†ç±»ç»Ÿè®¡\n\næ•°æ®ç»Ÿè®¡ä¸­ï¼Œæ•¬è¯·æœŸå¾…...\n"
    
    # æ·»åŠ POC/EXPç»Ÿè®¡
    if poc_exp_stats:
        md_content += "\n## ğŸ› ï¸ POC/EXPç»Ÿè®¡ï¼ˆåŸºäºä»“åº“æ ‡ç­¾å’Œæè¿°å†…å®¹åˆ†æï¼‰\n\n| ç±»å‹ | æ•°é‡ | å æ¯” |\n|:---|:---|:---|\n"
        total_poc_exp = sum(poc_exp_stats.values())
        for p_type, count in poc_exp_stats.items():
            percentage = (count / total_poc_exp * 100) if total_poc_exp > 0 else 0
            md_content += f"| {p_type} | {count:,} | {percentage:.1f}% |\n"
    else:
        md_content += "\n## ğŸ› ï¸ POC/EXPç»Ÿè®¡\n\næ•°æ®ç»Ÿè®¡ä¸­ï¼Œæ•¬è¯·æœŸå¾…...\n"
    
    # æ·»åŠ å‚å•†/äº§å“ç»Ÿè®¡ï¼ˆæ›¿ä»£æŠ€æœ¯æ ˆæŒ‡çº¹ç»Ÿè®¡ï¼‰
    vendor_product_stats = stats.get('vendor_product_stats', {})
    if vendor_product_stats:
        # å‚å•†ç»Ÿè®¡
        vendors = vendor_product_stats.get('vendors', {})
        products = vendor_product_stats.get('products', {})
        pairs = vendor_product_stats.get('vendor_product_pairs', {})
        
        md_content += "\n## ğŸ¢ å‚å•†/äº§å“ç»Ÿè®¡ï¼ˆåŸºäºCVEå®˜æ–¹APIï¼‰\n\n"
        
        # å‚å•†ç»Ÿè®¡
        if vendors:
            md_content += "### å‚å•†ç»Ÿè®¡Top 15\n\n| å‚å•† | æ¼æ´æ•°é‡ | å æ¯” |\n|:---|:---|:---|\n"
            total_vendors = sum(vendors.values())
            for vendor, count in vendors.items():
                percentage = (count / total_vendors * 100) if total_vendors > 0 else 0
                md_content += f"| {vendor} | {count:,} | {percentage:.1f}% |\n"
        
        # äº§å“ç»Ÿè®¡
        if products:
            md_content += "\n### äº§å“ç»Ÿè®¡Top 15\n\n| äº§å“ | æ¼æ´æ•°é‡ | å æ¯” |\n|:---|:---|:---|\n"
            total_products = sum(products.values())
            for product, count in products.items():
                percentage = (count / total_products * 100) if total_products > 0 else 0
                md_content += f"| {product} | {count:,} | {percentage:.1f}% |\n"
        
        # å‚å•†-äº§å“å¯¹ç»Ÿè®¡
        if pairs:
            md_content += "\n### å‚å•†-äº§å“ç»„åˆTop 10\n\n| å‚å•† - äº§å“ | æ¼æ´æ•°é‡ |\n|:---|:---|\n"
            for pair, count in pairs.items():
                md_content += f"| {pair} | {count:,} |\n"
    else:
        md_content += "\n## ğŸ¢ å‚å•†/äº§å“ç»Ÿè®¡\n\næ•°æ®ç»Ÿè®¡ä¸­ï¼Œæ•¬è¯·æœŸå¾…...\n"
    
    # æ·»åŠ æ•°æ®è·å–æ¶æ„è¯´æ˜
    md_content += """\n## ğŸ’¡ æ•°æ®è·å–æ¶æ„

ç³»ç»Ÿé‡‡ç”¨é«˜æ•ˆçš„æ•°æ®è·å–å’Œç¼“å­˜æœºåˆ¶ï¼š

### æ ¸å¿ƒç‰¹ç‚¹
- **è‡ªåŠ¨åŒ–æ›´æ–°**: é€šè¿‡GitHub Actionså®šæ—¶è·å–å¹¶å¤„ç†æ•°æ®
- **é™æ€æ–‡ä»¶ç¼“å­˜**: æ•°æ®å­˜å‚¨ä¸ºJSONæ–‡ä»¶ï¼Œæé«˜è®¿é—®é€Ÿåº¦
- **æ— Tokenä¾èµ–**: å‰ç«¯ç›´æ¥åŠ è½½é™æ€æ•°æ®ï¼Œæ— éœ€APIå¯†é’¥
- **å®æ—¶ç»Ÿè®¡**: è‡ªåŠ¨ç”Ÿæˆå¤šç»´åº¦ç»Ÿè®¡åˆ†æ
- **CWEåˆ†ç±»æ”¯æŒ**: åŸºäºCommon Weakness Enumerationæ ‡å‡†çš„æ¼æ´åˆ†ç±»
- **æŠ€æœ¯æ ˆæŒ‡çº¹è¯†åˆ«**: å‚è€ƒFingerprintHubçš„æŒ‡çº¹åº“æ¦‚å¿µï¼Œå®ç°æŠ€æœ¯æ ˆå…³è”åˆ†æ

### æ€§èƒ½ä¼˜åŠ¿
- é¡µé¢åŠ è½½é€Ÿåº¦æå‡çº¦80%
- é¿å…GitHub APIé€Ÿç‡é™åˆ¶é—®é¢˜
- æé«˜ç³»ç»Ÿç¨³å®šæ€§å’Œå¯é æ€§
- æ”¯æŒç¦»çº¿è®¿é—®å·²ç¼“å­˜æ•°æ®

## ğŸ”¬ ç»Ÿè®¡æ–¹æ³•è¯´æ˜

### CWEæ¼æ´åˆ†ç±»
æœ¬ç³»ç»Ÿé‡‡ç”¨Common Weakness Enumeration (CWE) æ ‡å‡†è¿›è¡Œæ¼æ´åˆ†ç±»ï¼Œä¸»è¦åŸºäºï¼š
- ä¼˜å…ˆä»CVEå®˜æ–¹APIè·å–CWE IDå’Œåˆ†ç±»ä¿¡æ¯
- åŸºäºTop 25+ CWEåˆ†ç±»æ˜ å°„åˆ°ä¸­æ–‡ç±»å‹
- å¢å¼ºçš„å…³é”®è¯æ¨¡å¼åŒ¹é…è¡¥å……

### å‚å•†/äº§å“ç»Ÿè®¡
é€šè¿‡CVEå®˜æ–¹APIè·å–å‡†ç¡®çš„å‚å•†å’Œäº§å“ä¿¡æ¯ï¼š
- åˆ©ç”¨ https://cveawg.mitre.org/api/cve/ æ¥å£
- æå–affectedå­—æ®µä¸­çš„vendorå’Œproductä¿¡æ¯
- ç»Ÿè®¡å‚å•†ã€äº§å“ä»¥åŠå‚å•†-äº§å“ç»„åˆæ•°æ®
- åŒ…å«APIè¯·æ±‚é‡è¯•å’Œè¶…æ—¶æ§åˆ¶æœºåˆ¶

### POC/EXPè¯†åˆ«å¢å¼º
é‡‡ç”¨å¤šç»´åº¦æŒ‡æ ‡åˆ¤æ–­POC/EXPå¯ç”¨æ€§ï¼š
- ä»“åº“æ ‡ç­¾åˆ†æï¼ˆé«˜æƒé‡æŒ‡æ ‡ï¼‰
- æ–‡ä»¶æ‰©å±•åå’Œå‘½åæ¨¡å¼
- æè¿°å†…å®¹çš„å…³é”®è¯å¯†åº¦
- ä»“åº“åç§°è¯­ä¹‰åˆ†æ
"""
    
    # æ·»åŠ è¯´æ˜
    md_content += "\n## â„¹ï¸ æ•°æ®è¯´æ˜\n- æ•°æ®æ¥æºäºæ¯æ—¥ä»GitHubæ”¶é›†çš„CVEä¿¡æ¯\n- ç»Ÿè®¡åŸºäºå·²æ”¶é›†çš„æ•°æ®ï¼Œå¯èƒ½å­˜åœ¨å»¶è¿Ÿ\n- CWEåˆ†ç±»ä¼˜å…ˆä»å®˜æ–¹APIè·å–ï¼Œå‡†ç¡®æ€§æ˜¾è‘—æé«˜\n- å‚å•†/äº§å“ç»Ÿè®¡åŸºäºCVEå®˜æ–¹æ•°æ®ï¼Œå¯é æ€§é«˜\n- ç»Ÿè®¡æ•°æ®æ¯æ—¥è‡ªåŠ¨æ›´æ–°\n- ç³»ç»Ÿç‰ˆæœ¬ï¼šv3.0 - åŸºäºCVE APIçš„å‚å•†/äº§å“ç²¾ç¡®ç»Ÿè®¡"
    
    # ä¿å­˜Markdownæ–‡ä»¶
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_md_path)
        if output_dir and not os.path.exists(output_dir):
            print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
            os.makedirs(output_dir, exist_ok=True)
        
        with open(output_md_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        print(f"âœ… Wikiç»Ÿè®¡Markdownå·²ç”Ÿæˆ: {output_md_path}")
        return True
    except Exception as e:
        print(f"âŒ ç”ŸæˆMarkdownå¤±è´¥: {e}")
        return False

def main():
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    
    # è®¾ç½®é»˜è®¤è·¯å¾„ä¸ºç»å¯¹è·¯å¾„ - ä½¿ç”¨å°å†™çš„dataç›®å½•
    default_summary = os.path.join(project_root, 'docs', 'data', 'daily', 'daily_summary.json')
    default_daily_dir = os.path.join(project_root, 'docs', 'data', 'daily')
    default_output_json = os.path.join(project_root, 'docs', 'data', 'statistics', 'wiki_stats.json')
    default_output_md = os.path.join(project_root, 'wiki_content', 'ç»Ÿè®¡æ•°æ®.md')
    
    parser = argparse.ArgumentParser(description='Wikiç»Ÿè®¡æ•°æ®ç”Ÿæˆå™¨')
    parser.add_argument('--summary', '-s',
                       default=default_summary,
                       help=f'æ¯æ—¥æ±‡æ€»æ–‡ä»¶è·¯å¾„ (é»˜è®¤: {default_summary})')
    parser.add_argument('--daily-dir', '-d',
                       default=default_daily_dir,
                       help=f'æ¯æ—¥æ•°æ®ç›®å½• (é»˜è®¤: {default_daily_dir})')
    parser.add_argument('--output-json', '-j',
                       default=default_output_json,
                       help=f'è¾“å‡ºç»Ÿè®¡JSONæ–‡ä»¶è·¯å¾„ (é»˜è®¤: {default_output_json})')
    parser.add_argument('--output-md', '-m',
                       default=default_output_md,
                       help=f'è¾“å‡ºWiki Markdownæ–‡ä»¶è·¯å¾„ (é»˜è®¤: {default_output_md})')
    parser.add_argument('--days', '-n',
                       type=int, default=30,
                       help='ç»Ÿè®¡å¤©æ•° (é»˜è®¤: 30)')
    
    args = parser.parse_args()
    
    print("ğŸš€ GitHub CVE Monitor - Wikiç»Ÿè®¡æ•°æ®ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # åŠ è½½æ±‡æ€»æ•°æ®
    print(f"ğŸ“Š åŠ è½½æ±‡æ€»æ•°æ®: {args.summary}")
    summary = load_daily_summary(args.summary)
    if not summary:
        print("âŒ æ— æ³•åŠ è½½æ±‡æ€»æ•°æ®ï¼Œè„šæœ¬é€€å‡º")
        return 1
    
    # åŠ è½½æ¯æ—¥æ•°æ®
    print(f"ğŸ“… åŠ è½½æœ€è¿‘{args.days}å¤©çš„æ¯æ—¥æ•°æ®...")
    daily_files = load_daily_files(args.daily_dir, args.days)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(daily_files)} ä¸ªæ¯æ—¥æ•°æ®æ–‡ä»¶")
    
    # ç”Ÿæˆç»Ÿè®¡æ•°æ®
    print("ğŸ“ˆ ç”Ÿæˆç»Ÿè®¡æ•°æ®...")
    stats = generate_stats_file(summary, daily_files, args.output_json)
    if not stats:
        print("âŒ ç»Ÿè®¡æ•°æ®ç”Ÿæˆå¤±è´¥")
        return 1
    
    # ç”ŸæˆWiki Markdown
    print("ğŸ“ ç”ŸæˆWikiç»Ÿè®¡Markdown...")
    if generate_wiki_md(stats, args.output_md):
        print("\nâœ… æ‰€æœ‰ç»Ÿè®¡æ•°æ®å·²æˆåŠŸç”Ÿæˆï¼")
        return 0
    else:
        print("\nâŒ Wiki Markdownç”Ÿæˆå¤±è´¥")
        return 1

if __name__ == '__main__':
    exit(main())