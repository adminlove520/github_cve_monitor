from functools import total_ordering
import requests
from peewee import *
from datetime import datetime
import html
import time
import random
import math
import re
import os
import locale
from pathlib import Path
import json

# è®¾ç½®ä¸­æ–‡ç¯å¢ƒ
try:
    locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'Chinese_China.936')
    except:
        pass  # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤

db = SqliteDatabase("db/cve.sqlite")

class CVE_DB(Model):
    id = IntegerField()
    full_name = CharField(max_length=1024)
    description = CharField(max_length=4098)
    url = CharField(max_length=1024)
    created_at = CharField(max_length=128)
    cve = CharField(max_length=64)

    class Meta:
        database = db

db.connect()
db.create_tables([CVE_DB])

def init_file():
    newline = "# Github CVE Monitor\n\n> Automatic monitor github cve using Github Actions \n\n Last generated : {}\n\n| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |\n|---|---|---|---|\n".format(datetime.now())
    with open('docs/README.md','w', encoding='utf-8') as f:
        f.write(newline) 
    f.close()

def write_file(new_contents, overwrite=False):
    mode = 'w' if overwrite else 'a'
    with open('docs/README.md', mode, encoding='utf-8') as f:
        f.write(new_contents)
    f.close()

def init_daily_file(date_str):
    """åˆå§‹åŒ–æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶"""
    # åˆ›å»ºæ—¥æœŸç›®å½•
    today = datetime.now()
    year = today.year
    week_number = today.strftime("%W")
    month = today.strftime("%m")
    day = today.strftime("%d")
    
    # åˆ›å»ºç›®å½•ç»“æ„ /Data/YYYY-W-mm-dd
    dir_path = f"docs/Data/{year}-W{week_number}-{month}-{day}"
    Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    file_path = f"{dir_path}/daily_{date_str}.md"
    newline = f"""# æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Š ({date_str})

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHub CVE æ•°æ®åº“

## ä»Šæ—¥ æƒ…æŠ¥é€Ÿé€’

| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(newline)
    
    return file_path

def write_daily_file(file_path, new_contents):
    """å†™å…¥æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šæ–‡ä»¶"""
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(new_contents)
    f.close()

def update_daily_index():
    """æ›´æ–°æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šç´¢å¼•æ–‡ä»¶"""
    data_dir = Path("docs/Data")
    if not data_dir.exists():
        return
    
    # åˆ›å»ºç´¢å¼•æ–‡ä»¶
    index_path = data_dir / "index.md"
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write("# æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šç´¢å¼•\n\n")
        f.write("> Automatic monitor Github CVE using Github Actions\n\n")
        f.write("## å¯ç”¨æŠ¥å‘Š\n\n")
    
    # éå†æ‰€æœ‰æ—¥æœŸç›®å½•
    date_dirs = sorted([d for d in data_dir.glob("*-W*-*-*")], reverse=True)
    
    for date_dir in date_dirs:
        dir_name = date_dir.name
        with open(index_path, 'a', encoding='utf-8') as f:
            f.write(f"### {dir_name}\n\n")
        
        # éå†è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰dailyæŠ¥å‘Š
        daily_files = sorted([f for f in date_dir.glob("daily_*.md")], reverse=True)
        
        for daily_file in daily_files:
            file_name = daily_file.name
            relative_path = f"Data/{date_dir.name}/{file_name}"
            date_str = file_name.replace("daily_", "").replace(".md", "")
            
            # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
            try:
                formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
            except:
                formatted_date = date_str
            
            with open(index_path, 'a', encoding='utf-8') as f:
                f.write(f"- [{formatted_date} æ¯æ—¥æŠ¥å‘Š]({relative_path})\n")
        
        with open(index_path, 'a', encoding='utf-8') as f:
            f.write("\n")
    
    # æ›´æ–°ä¾§è¾¹æ ï¼Œæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥
    update_sidebar()

def update_sidebar():
    """æ›´æ–°ä¾§è¾¹æ ï¼Œæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥"""
    sidebar_path = Path("docs/_sidebar.md")
    if not sidebar_path.exists():
        return
    
    # è¯»å–ç°æœ‰ä¾§è¾¹æ å†…å®¹
    with open(sidebar_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ¯æ—¥æŠ¥å‘Šé“¾æ¥
    daily_report_exists = False
    for line in lines:
        if "æ¯æ—¥æŠ¥å‘Š" in line:
            daily_report_exists = True
            break
    
    # å¦‚æœæ²¡æœ‰æ¯æ—¥æŠ¥å‘Šé“¾æ¥ï¼Œæ·»åŠ åˆ°ä¾§è¾¹æ 
    if not daily_report_exists:
        # æ‰¾åˆ°åˆé€‚çš„ä½ç½®æ’å…¥é“¾æ¥
        new_lines = []
        for line in lines:
            new_lines.append(line)
            # åœ¨ä¸»é¡µé“¾æ¥åæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥
            if "- [ä¸»é¡µ](README.md)" in line or "- [Home](README.md)" in line:
                new_lines.append("- [æ¯æ—¥æŠ¥å‘Š](/Data/index.md)\n")
        
        # å†™å›æ–‡ä»¶
        with open(sidebar_path, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)

def load_config():
    """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®ä¿¡æ¯"""
    config_paths = [
        "docs/Data/config.json",
        "docs/config.json",
        "config.json"
    ]
    
    for config_path in config_paths:
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    return config
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è¯»å–é…ç½®æ–‡ä»¶ {config_path}: {e}")
    
    return {}

def get_github_token():
    """è·å–GitHub Tokenï¼Œä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ > é…ç½®æ–‡ä»¶"""
    # é¦–å…ˆæ£€æŸ¥ç¯å¢ƒå˜é‡
    github_token = os.environ.get('GITHUB_TOKEN')
    if github_token:
        print(f"DEBUG: ä»ç¯å¢ƒå˜é‡è·å–åˆ°GITHUB_TOKEN")
        print(f"DEBUG: Tokené•¿åº¦: {len(github_token)}")
        # ä¸è¦æ‰“å°å®Œæ•´çš„tokenï¼Œä½†å¯ä»¥æ‰“å°å‰å‡ ä¸ªå­—ç¬¦æ¥ç¡®è®¤
        if len(github_token) > 5:
            print(f"DEBUG: Tokenå‰ç¼€: {github_token[:5]}...")
        return github_token
    
    # ç„¶åæ£€æŸ¥é…ç½®æ–‡ä»¶
    config = load_config()
    github_token = config.get('github_token')
    if github_token and github_token != "your_token_here":
        print(f"DEBUG: ä»é…ç½®æ–‡ä»¶è·å–åˆ°github_token")
        print(f"DEBUG: Tokené•¿åº¦: {len(github_token)}")
        if len(github_token) > 5:
            print(f"DEBUG: Tokenå‰ç¼€: {github_token[:5]}...")
        return github_token
    
    print("DEBUG: æœªæ‰¾åˆ°æœ‰æ•ˆçš„GitHub Token")
    return None

def get_info(year):
    try:
        all_items = []
        page = 1
        per_page = 100 # é»˜è®¤æ¯é¡µ100æ¡ï¼Œæœ‰tokenæ—¶ä½¿ç”¨
        github_token = get_github_token()
        headers = {}

        if github_token:
            print(f"DEBUG: GITHUB_TOKEN is set. Value: {github_token[:5]}...") # Print partial token for security
            headers['Authorization'] = f'token {github_token}'
            print(f"Using GitHub Token for authentication (Year: {year})")
        else:
            print("DEBUG: GITHUB_TOKEN is NOT set.")
            per_page = 30 # æ— tokenæ—¶æ¯é¡µ30æ¡
            print(f"No GitHub Token found, using unauthenticated request (Year: {year})")

        print("DEBUG: os.environ content:")
        for key, value in os.environ.items():
            if "GITHUB" in key.upper(): # Only print relevant environment variables
                print(f"  {key}: {value[:10]}...")

        # æ·»åŠ è¯·æ±‚å¤´çš„è°ƒè¯•ä¿¡æ¯
        print(f"DEBUG: è¯·æ±‚å¤´: {headers}")
        
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            api = f"https://api.github.com/search/repositories?q=CVE-{year}&sort=updated&page={page}&per_page={per_page}"
            print(f"DEBUG: APIè¯·æ±‚URL: {api}")
            response = requests.get(api, headers=headers)

            # æ‰“å°è¯¦ç»†çš„å“åº”ä¿¡æ¯ç”¨äºè°ƒè¯•
            print(f"DEBUG: APIè¯·æ±‚çŠ¶æ€ç : {response.status_code}")
            
            if 'X-RateLimit-Limit' in response.headers:
                remaining = response.headers.get('X-RateLimit-Remaining')
                limit = response.headers.get('X-RateLimit-Limit')
                print(f"API Rate Limit: {remaining}/{limit}")
                
                # å¦‚æœå‰©ä½™è¯·æ±‚æ¬¡æ•°å¾ˆå°‘ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´
                if remaining and int(remaining) < 10:
                    print(f"è­¦å‘Š: æ¥è¿‘é€Ÿç‡é™åˆ¶ï¼Œå‰©ä½™è¯·æ±‚æ¬¡æ•°: {remaining}")
                    time.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿ

            # å¤„ç†403é”™è¯¯
            if response.status_code == 403:
                print(f"é”™è¯¯: GitHub APIè¿”å›403 Forbidden")
                print(f"å“åº”å†…å®¹: {response.text}")
                if 'X-GitHub-SSO' in response.headers:
                    print(f"SSOè¦æ±‚: {response.headers.get('X-GitHub-SSO')}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
                if 'rate limit' in response.text.lower():
                    print("æ£€æµ‹åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•...")
                    time.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿåå†é‡è¯•
                    retry_count += 1
                    continue
                else:
                    break

            # å¤„ç†401é”™è¯¯ï¼ˆè®¤è¯å¤±è´¥ï¼‰
            if response.status_code == 401:
                print(f"é”™è¯¯: GitHub APIè¿”å›401 Unauthorized")
                print(f"å“åº”å†…å®¹: {response.text}")
                break

            req = response.json()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
            if "message" in req:
                print(f"APIå“åº”æ¶ˆæ¯: {req['message']}")
                # å¦‚æœæ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
                if "rate limit" in req['message'].lower() or "limit" in req['message'].lower():
                    print("æ£€æµ‹åˆ°é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•...")
                    time.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿåå†é‡è¯•
                    retry_count += 1
                    continue

            items = req.get("items")

            if not items:
                break

            all_items.extend(items)

            # å¦‚æœå½“å‰é¡µè¿”å›çš„itemæ•°é‡å°äºper_pageï¼Œè¯´æ˜å·²ç»æ˜¯æœ€åä¸€é¡µ
            if len(items) < per_page:
                break
            
            page += 1
            # éšæœºç­‰å¾…ä»¥é¿å…APIé™åˆ¶ (ä»…åœ¨æ— tokenæ—¶ç­‰å¾…)
            if not github_token:
                count = random.randint(3, 15)
                time.sleep(count)
            else:
                # æœ‰tokenæ—¶ä¹Ÿç¨å¾®ç­‰å¾…ï¼Œé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
                time.sleep(1)

            retry_count = 0  # é‡ç½®é‡è¯•è®¡æ•°

        return all_items
    except Exception as e:
        print("An error occurred in the network request", e)
        return None


def db_match(items):
    r_list = []
    regex = r"[Cc][Vv][Ee][-_]\d{4}[-_]\d{4,7}"
    cve = ''
    for item in items:
        id = item["id"]
        if CVE_DB.select().where(CVE_DB.id == id).count() != 0:
            continue
        full_name = html.escape(item["full_name"])
        description = item["description"]
        if description == "" or description == None:
            description = 'no description'
        else:
            description = html.escape(description.strip())
        url = item["html_url"]
### EXTRACT CVE 
        matches = re.finditer(regex, url, re.MULTILINE)
        for matchNum, match in enumerate(matches, start=1):
            cve = match.group()
        if not cve:
            matches = re.finditer(regex, description, re.MULTILINE)
            cve = "CVE Not Found"
            for matchNum, match in enumerate(matches, start=1):
                cve = match.group()
### 
        created_at = item["created_at"]
        r_list.append({
            "id": id,
            "full_name": full_name,
            "description": description,
            "url": url,
            "created_at": created_at,
            "cve": cve.replace('_','-')
        })
        CVE_DB.create(id=id,
                      full_name=full_name,
                      description=description,
                      url=url,
                      created_at=created_at,
                      cve=cve.upper().replace('_','-'))

    return sorted(r_list, key=lambda e: e.__getitem__('created_at'))

def init_others_file():
    """åˆå§‹åŒ–others.mdæ–‡ä»¶"""
    newline = f"""# å…¶ä»–æœªè¯†åˆ«CVEç¼–å·çš„ä»“åº“æŠ¥å‘Š

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHubä»“åº“ï¼ˆæœªè¯†åˆ«CVEç¼–å·ï¼‰
- **è¯´æ˜**: æœ¬æŠ¥å‘ŠåŒ…å«åœ¨GitHubä¸Šæ‰¾åˆ°ä½†æœªèƒ½æå–æœ‰æ•ˆCVEç¼–å·çš„ä»“åº“ä¿¡æ¯

## ä»“åº“åˆ—è¡¨

| çŠ¶æ€ | ç›¸å…³ä»“åº“ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    with open('docs/others.md', 'w', encoding='utf-8') as f:
        f.write(newline)
    f.close()

def write_others_file(new_contents):
    """å†™å…¥others.mdæ–‡ä»¶"""
    with open('docs/others.md', 'a', encoding='utf-8') as f:
        f.write(new_contents)
    f.close()

def main():
    # è·å–å½“å‰æ—¥æœŸ
    today = datetime.now()
    date_str = today.strftime("%Y%m%d")
    year = today.year
    
    # åˆå§‹åŒ–å…¨é‡æ•°æ®æ–‡ä»¶
    init_file()

    # åˆå§‹åŒ–æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    daily_file_path = init_daily_file(date_str)
    
    # åˆå§‹åŒ–othersæ–‡ä»¶
    init_others_file()

    # æ”¶é›†æ•°æ®
    sorted_list = []
    today_list = []  # å­˜å‚¨å½“æ—¥æ•°æ®
    others_list = []  # å­˜å‚¨CVEç¼–å·ä¸ºç©ºçš„æ•°æ®
    
    # é¦–å…ˆè·å–å½“å¹´çš„æ•°æ®ï¼ˆå½“æ—¥æ•°æ®ï¼‰
    print(f"è·å–å½“å¹´ ({year}) çš„CVEæ•°æ®...")
    item = get_info(year)
    if item is not None and len(item) > 0:
        print(f"å¹´ä»½: {year} : è·å–åˆ° {len(item)} æ¡åŸå§‹æ•°æ®")
        sorted_data = db_match(item)
        if len(sorted_data) != 0:
            print(f"å¹´ä»½ {year} : æ›´æ–° {len(sorted_data)} æ¡è®°å½•")
            
            # ç­›é€‰å½“æ—¥æ•°æ®
            for entry in sorted_data:
                try:
                    created_date = datetime.fromisoformat(entry["created_at"].replace("Z", "+00:00"))
                    # åˆ¤æ–­æ˜¯å¦ä¸ºå½“æ—¥æ•°æ®ï¼ˆä½¿ç”¨æ—¥æœŸå­—ç¬¦ä¸²æ¯”è¾ƒï¼Œè€ƒè™‘åˆ°2025-09-22T13:53:14Zè¿™æ ·çš„æ ¼å¼ï¼‰
                    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä½¿ç”¨created_dateçš„æ—¥æœŸï¼Œä¸è½¬æ¢ä¸ºæœ¬åœ°æ—¶é—´
                    created_date_str = created_date.strftime("%Y-%m-%d")
                    today_str = today.strftime("%Y-%m-%d")
                    if created_date_str == today_str:
                        today_list.append(entry)
                except Exception as e:
                    print(f"æ—¥æœŸè§£æé”™è¯¯: {e}")
            
            sorted_list.extend(sorted_data)
        
        # éšæœºç­‰å¾…ä»¥é¿å…APIé™åˆ¶
        count = random.randint(3, 15)
        time.sleep(count)
    
    # è·å–å†å²æ•°æ®
    # é™åˆ¶å¹´ä»½èŒƒå›´åˆ°2020-2025ï¼Œå› ä¸ºä¹‹å‰çš„æ•°æ®ä»·å€¼è¾ƒå°
    start_year = max(2020, year-1)  # ä¸æ—©äº2020å¹´
    end_year = max(2020, year-5)    # æœ€å¤šè·å–5å¹´å‰çš„æ•°æ®ï¼Œä½†ä¸æ—©äº2020å¹´
    
    for i in range(start_year, end_year-1, -1):
        item = get_info(i)
        if item is None or len(item) == 0:
            continue
        print(f"å¹´ä»½: {i} : è·å–åˆ° {len(item)} æ¡åŸå§‹æ•°æ®")
        sorted_data = db_match(item)
        if len(sorted_data) != 0:
            print(f"å¹´ä»½ {i} : æ›´æ–° {len(sorted_data)} æ¡è®°å½•")
            sorted_list.extend(sorted_data)
        count = random.randint(3, 15)
        time.sleep(count)
    
    # ç”Ÿæˆå…¨é‡æ•°æ®æŠ¥å‘Š
    cur = db.cursor()
    cur.execute("SELECT * FROM CVE_DB ORDER BY cve DESC;")
    result = cur.fetchall()
    
    # åˆ†ç¦»æœ‰CVEç¼–å·å’Œæ— CVEç¼–å·çš„æ•°æ®
    valid_cve_records = []
    others_records = []
    
    for row in result:
        if row[5].upper() == "CVE NOT FOUND":
            others_records.append(row)
        else:
            valid_cve_records.append(row)
    
    # å†™å…¥æŠ¥å‘Šå¤´éƒ¨
    newline = f"""# å…¨é‡ æƒ…æŠ¥é€Ÿé€’ æ•°æ®æŠ¥å‘Š

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHub CVE æ•°æ®åº“
- **æ€»è®°å½•æ•°**: {len(valid_cve_records)}
- **å…¶ä»–è®°å½•æ•°**: {len(others_records)} (è¯¦è§ [others.md](./others.md))

## å…¨é‡æ•°æ®æŠ¥å‘Š

| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    write_file(newline, overwrite=True) # é¦–æ¬¡å†™å…¥æ—¶è¦†ç›–æ–‡ä»¶

    # å†™å…¥æœ‰æ•ˆçš„CVEè®°å½•
    for row in valid_cve_records:
        Publish_Date = row[4]
        Description = row[2].replace('|','-')
        newline = "| [" + row[5].upper() + "](https://www.cve.org/CVERecord?id=" + row[5].upper() + ") | [" + row[1] + "](" + row[3] + ") | " + Description + " | " + Publish_Date + "|\n"
        write_file(newline)
    
    # ç”Ÿæˆothers.mdæŠ¥å‘Š
    if len(others_records) > 0:
        for row in others_records:
            Publish_Date = row[4]
            Description = row[2].replace('|','-')
            newline = "| ğŸš« æœªè¯†åˆ« | [" + row[1] + "](" + row[3] + ") | " + Description + " | " + Publish_Date + "|\n"
            write_others_file(newline)
        
        # æ·»åŠ æŠ¥å‘Šå°¾éƒ¨
        footer = f"\n\n---\n\n**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n**æ€»è®°å½•æ•°**: {len(others_records)}\n"
        write_others_file(footer)
    
    # ç”Ÿæˆå½“æ—¥æŠ¥å‘Š
    
    # è®°å½•åŸå§‹today_listé•¿åº¦
    original_today_list_len = len(today_list)
    print(f"ç”Ÿæˆå½“æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šï¼Œå…± {len(today_list)} æ¡è®°å½•")
    
    # å¦‚æœå½“æ—¥æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æœ€è¿‘çš„æ•°æ®
    if len(today_list) == 0:
        print("å½“æ—¥æ— æ•°æ®ï¼Œå°è¯•è·å–æœ€è¿‘7å¤©çš„æ•°æ®...")
        # å…ˆå°è¯•è·å–æœ€è¿‘7å¤©çš„æ•°æ®
        cur = db.cursor()
        # è·å–7å¤©å†…çš„æ•°æ®
        from datetime import timedelta
        seven_days_ago = (today - timedelta(days=7)).strftime("%Y-%m-%d")
        cur.execute(f"SELECT * FROM CVE_DB WHERE created_at >= '{seven_days_ago}' ORDER BY created_at DESC;")
        recent_records = cur.fetchall()
        
        # å¦‚æœ7å¤©å†…æ²¡æœ‰æ•°æ®ï¼Œåˆ™è·å–æœ€è¿‘çš„10æ¡è®°å½•
        if len(recent_records) == 0:
            print("æœ€è¿‘7å¤©æ— æ•°æ®ï¼Œè·å–æœ€è¿‘10æ¡è®°å½•...")
            cur.execute("SELECT * FROM CVE_DB ORDER BY created_at DESC LIMIT 10;")
            recent_records = cur.fetchall()
        
        # è½¬æ¢ä¸ºä¸today_listç›¸åŒçš„æ ¼å¼
        for row in recent_records:
            today_list.append({
                "cve": row[5],
                "full_name": row[1],
                "description": row[2],
                "url": row[3],
                "created_at": row[4]
            })
        
        print(f"å½“æ—¥æ— æ•°æ®ï¼Œä½¿ç”¨æœ€è¿‘ {len(today_list)} æ¡è®°å½•")
    
    # å†™å…¥æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    if len(today_list) > 0:
        print(f"æˆåŠŸå†™å…¥ {len(today_list)} æ¡è®°å½•åˆ°æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Š")

    # å†™å…¥æ¯æ—¥æŠ¥å‘Šï¼ˆè¿‡æ»¤æ‰CVE NOT FOUNDçš„è®°å½•ï¼‰
    valid_today_list = [entry for entry in today_list if entry["cve"].upper() != "CVE NOT FOUND"]
    
    for entry in valid_today_list:
        cve = entry["cve"]
        full_name = entry["full_name"]
        description = entry["description"].replace('|','-')
        url = entry["url"]
        created_at = entry["created_at"]

        newline = f"| [{cve.upper()}](https://www.cve.org/CVERecord?id={cve.upper()}) | [{full_name}]({url}) | {description} | {created_at}|\n"

        # å†™å…¥æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
        write_daily_file(daily_file_path, newline)

    # å¦‚æœæ˜¯ä½¿ç”¨æœ€è¿‘è®°å½•ï¼Œåˆ™åœ¨æŠ¥å‘Šä¸­å¢åŠ è¯´æ˜ (ç§»åŠ¨åˆ°æ­¤å¤„)
    if original_today_list_len == 0:
        with open(daily_file_path, 'a', encoding='utf-8') as f:
            f.write("\n\n> ç”±äºæ²¡æœ‰è·å–åˆ°å½“æ—¥æ•°æ®ï¼Œä½¿ç”¨è¿‘7å¤©è®°å½•\n\n")

    # æ›´æ–°ç´¢å¼•æ–‡ä»¶ï¼Œåˆ—å‡ºæ‰€æœ‰æ¯æ—¥æŠ¥å‘Š
    update_daily_index()

    # Statistics
    ## TODO HERE WILL COME THE CODE FOR STATISTICS 

if __name__ == "__main__":
    # init_file() # ç§»é™¤æ­¤è¡Œï¼Œå› ä¸ºå…¨é‡æŠ¥å‘Šçš„å†™å…¥ä¼šè¦†ç›–æ–‡ä»¶
    main()
